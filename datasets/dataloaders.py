"""
Pytorch dataloader for loading datasets created through WildMix.

Contributors:
    Tianjun Ma (tianjunm@cs.cmu.edu)

"""


import copy
import os
import numpy as np
import pandas as pd
from torch.utils.data import Dataset
from mmsdk import mmdatasdk


DATA_ROOT = '/results/tianjunm/datasets'


class WildMix(Dataset):
    """This dataset loads the mixture-ground truth pairs.

    Loads specified dataset generated by Wild-Mix.
    """

    def __init__(self, dataset_config, dataset_split, transform=None):
        self._config = dataset_config
        self._raw_data = self._load_raw()
        self._datapoints = self._load_augmentation(self._config, dataset_split)
        self._transform = transform

    def __len__(self):
        nsrc = self._config['num_sources']
        assert len(self._datapoints) % nsrc == 0

        return len(self._datapoints) // nsrc

    def __getitem__(self, idx):
        ground_truths = []
        component_info = []
        nsrc = self._config['num_sources']

        # load [nsrc] rows from instruction
        begin, end = idx * nsrc, (idx + 1) * nsrc
        instances = self._datapoints.iloc[begin:end]

        for iid in instances.index:
            ground_truths.append(self._create_gt(instances, iid))
            component_info.append(instances.at[iid, 'category'])

        item = {
            'model_input': self._overlay(ground_truths),
            'ground_truths': ground_truths,
            'component_info': component_info
        }

        return self._transform(item)

    @property
    def input_shape(self):
        assert len(self) > 0

        input_shape = self[0]['model_input'].size()

        return input_shape

    def _create_gt(self, instances, iid):
        """Creates the ground truth.

        The ground truth is a clip from the original source, padded
        according to its placement within a mixture, specified by the
        dataset descriptor.

        """
        mixture_duration = self._config['mixture_duration']
        sr = self._config['sample_rate']

        category = instances.at[iid, 'category']
        sound_id = instances.at[iid, 'filename']
        duration = instances.at[iid, 'source_duration']
        start = instances.at[iid, 'source_start']
        placement = instances.at[iid, 'mixture_placement']

        raw_source = self._raw_data.computational_sequences[category][
                     sound_id]['features']

        ground_truth = self._pad(self._clip(raw_source, start, duration),
                                 mixture_duration * sr, placement)

        return ground_truth

    @staticmethod
    def _overlay(ground_truths):
        """Overlay ground truths together to create the aggregate."""
        aggregate = copy.deepcopy(ground_truths[0])
        for idx in range(1, len(ground_truths)):
            aggregate += ground_truths[idx]
        return aggregate

    @staticmethod
    def _load_raw():
        """Loads all raw data into memory."""

        path = os.path.join(DATA_ROOT,
                            'audioset_verified',
                            'csd_format',
                            'cut',
                            '16000')
        files = {}
        for csd_file in os.listdir(path):
            # category = csd_file
            files[csd_file] = os.path.join(path, csd_file)

        return mmdatasdk.mmdataset(files)

    @staticmethod
    def _load_augmentation(dataset_info, dataset_split):

        hashes = pd.read_csv(os.path.join(DATA_ROOT, 'wild-mix',
                                          'all_dataset_hashes.csv'))

        mix_method = dataset_info['mix_method']
        nsrc = dataset_info['num_sources']
        ncls = dataset_info['num_classes']

        md5 = hashes[(hashes.mixing_type == mix_method) &
                     (hashes.num_sources == nsrc) &
                     (hashes.num_classes == ncls)].hash_val.iloc[0]

        filename = f't{mix_method}-{nsrc}s-{ncls}c/{md5}/{dataset_split}.csv'
        path = os.path.join(DATA_ROOT, 'wild-mix', filename)
        print(md5)
        augmentation = pd.read_csv(path)

        return augmentation

    @staticmethod
    def _clip(raw_source, start, duration):
        n = raw_source.shape[1]  # number of frames
        # print(raw_source.shape)
        start_frame = int(start * n)
        clip = raw_source[:, start_frame:min(n, start_frame + duration)]
        return clip.flatten()

    @staticmethod
    def _pad(clip, mixture_length, placement):
        # follow the datapoint spec to create ground truths
        prefix = np.zeros(placement) * 1.0
        # print(mixture_length)
        # print(len(clip))
        # print(placement)
        suffix = np.zeros(mixture_length - len(clip) - placement) * 1.0

        # padded_wav = pad_before + wav + pad_after
        padded_clip = np.concatenate((prefix, clip, suffix), axis=None)

        assert len(padded_clip) == mixture_length

        return padded_clip
