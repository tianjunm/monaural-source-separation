{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import model.dataset as ds\n",
    "import model.models\n",
    "import scipy.spatial.distance as ssdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ds.SignalDataset(root_dir='/home/tianjunm/Documents/Projects/dataset/a1_spectrograms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(d, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, info in enumerate(dataloader):\n",
    "    aggregate = info['aggregate']\n",
    "    ground_truths = [gt for gt in info['ground_truths']]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 691, 258])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# agg = np.load('/home/tianjunm/Documents/Projects/dataset/a1_spectrograms/1000/gt/4.npy')\n",
    "\n",
    "# def concat(m):\n",
    "#     num_features, nrows, ncols = m.shape\n",
    "#     result = np.zeros((nrows*num_features, ncols))\n",
    "\n",
    "#     for i in range(num_features):\n",
    "#         start = i * nrows;\n",
    "#         end = (i + 1) * nrows;\n",
    "#         result[start:end, :] = m[i]\n",
    "#     return result\n",
    "\n",
    "# agg_concat = concat(agg)\n",
    "# aggregate = torch.t(torch.from_numpy(agg_concat))\n",
    "\n",
    "# # dataloader\n",
    "# aggregate = aggregate.unsqueeze(0).float()\n",
    "print(aggregate.size())\n",
    "bs, seq_len, input_dim = aggregate.size()\n",
    "\n",
    "net = model.models.Baseline(input_dim, seq_len=seq_len, num_sources=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each batch has a distance matrix [d * d]\n",
    "# number in each cell represents rank of each cell after sorting\n",
    "# use (?) algorithm to pick d cells\n",
    "import numpy as np\n",
    "# dists = np.array([[[1, 3, 4],\n",
    "#                    [2, 5, 6],\n",
    "#                    [7, 8, 9]],\n",
    "#                   [[5, 9, 8],\n",
    "#                    [4, 2, 6],\n",
    "#                    [3, 1, 7]]])\n",
    "# print(dists)\n",
    "\n",
    "def get_orders(dists):\n",
    "    '''\n",
    "    Args:\n",
    "        dists: [bs, n_sources n_sources]\n",
    "    '''\n",
    "    num_batches = dists.shape[0]\n",
    "    d = dists.shape[1]\n",
    "    orders = np.zeros(dists.shape)\n",
    "    for batch in range(num_batches):\n",
    "        flattened = np.copy(dists[batch, :, :].reshape(1, -1))\n",
    "        indices = np.argsort(flattened)\n",
    "        flattened[:, indices] = np.arange(flattened.size)\n",
    "        print(flattened.reshape(d, -1))\n",
    "        print(flattened.reshape(d, -1).astype(int))\n",
    "        orders[batch, :, :] = flattened.reshape(d, -1)\n",
    "    \n",
    "    return orders.astype(int)\n",
    "\n",
    "\n",
    "def get_matches(orders):\n",
    "    num_batches = orders.shape[0]\n",
    "    d = orders.shape[1]\n",
    "    mask = np.max(orders) + 1\n",
    "    \n",
    "    matched_pairs = np.zeros((num_batches, d))\n",
    "    for i in range(d):\n",
    "        for batch in range(num_batches):\n",
    "            m = np.argmin(orders[batch, :, :])\n",
    "            indices = np.array([(m // d), (m % d)])\n",
    "\n",
    "            matched_pairs[batch][indices[0]] = indices[1]\n",
    "\n",
    "            # mask row & col\n",
    "            orders[batch, indices[0], :] = np.ones(d) * mask\n",
    "            orders[batch, :, indices[1]] = np.ones(d) * mask\n",
    "    \n",
    "    return matched_pairs    \n",
    "\n",
    "# orders = get_orders(dists)\n",
    "# print(orders)\n",
    "# get_seq(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(x, seq_len, bs):\n",
    "    x = [x[:, ts, :] for ts in range(seq_len)]\n",
    "    x = torch.cat(x).view(seq_len, bs, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def flatten(ms, batch):\n",
    "    # n_sources * (seq_len * input_dim)\n",
    "    return np.array([m[:, batch, :].detach().numpy().flatten() for m in ms])\n",
    "\n",
    "\n",
    "def calc_dists(preds, gts, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        preds: n_sources * [seq_len, bs, input_dim]\n",
    "        gts: n_sources * [seq_len, bs, input_dim]\n",
    "    \n",
    "    Returns:\n",
    "        dists: [bs, n_sources]\n",
    "    \"\"\"\n",
    "    n_sources = len(preds)\n",
    "    assert n_sources == len(gts)\n",
    "\n",
    "    bs = preds[0].size()[1]\n",
    "\n",
    "    # getting the distances from each prediction to all gts\n",
    "    all_dists = np.zeros((bs, n_sources, n_sources))\n",
    "    \n",
    "    for batch in range(bs):\n",
    "        pred_flattened = flatten(preds, batch)\n",
    "        gt_flattened = flatten(gts, batch)\n",
    "        all_dists[batch] = ssdist.cdist(pred_flattened, gt_flattened)\n",
    "    \n",
    "#     print(all_dists)\n",
    "    all_orders = get_orders(all_dists)\n",
    "    print(all_orders)\n",
    "    all_matches = get_matches(all_orders)\n",
    "    \n",
    "\n",
    "#     print(all_matches)\n",
    "    dists = torch.zeros(bs, n_sources).to(device)\n",
    "    \n",
    "    for batch in range(bs):\n",
    "        matches = all_matches[batch]\n",
    "#         print(all_dists[batch])\n",
    "#         print(matches)\n",
    "        for src_id in range(n_sources):\n",
    "            pred = preds[src_id]\n",
    "            gt_match = gts[int(matches[src_id])]\n",
    "            # recomputing required to keep track of grads\n",
    "            dist = torch.norm(torch.squeeze(pred[:, batch, :] - gt_match[:, batch, :], dim=1), 2)\n",
    "            dists[batch, src_id] = dist\n",
    "\n",
    "#     for src_id in range(n_sources):\n",
    "#         pred = preds[src_id]\n",
    "# #         for batch in range(bs):\n",
    "# #             dist = torch.norm(torch.squeeze(pred[:, batch, :] - gt[:, batch, :], dim=1), 2)\n",
    "# #             dists[batch, src_id] = dist\n",
    "    \n",
    "#     matches get_seq(diss)\n",
    "        \n",
    "    return dists\n",
    "\n",
    "\n",
    "class MinLoss(nn.Module):\n",
    "    \"\"\"Custom loss function #1\n",
    "\n",
    "    Compare the distance from output with its closest ground truth.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, device):\n",
    "        # nn.Module.__init__(self)\n",
    "        super(MinLoss, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, predictions, ground_truths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prediction: num_sources * [seq_len, bs, input_dim]\n",
    "            ground_truths: num_sources * [bs, seq_len, input_dim] \n",
    "        Returns:\n",
    "            loss: [bs,]\n",
    "        \"\"\"\n",
    "        seq_len = predictions[0].size()[0]\n",
    "        bs = predictions[0].size()[1]\n",
    "        # reshape gts into seq_len, bs, input_dim\n",
    "        gts = [reshape(gt, seq_len, bs) for gt in ground_truths]\n",
    "\n",
    "        # get distance measure (bs * num_sources)\n",
    "        dists = calc_dists(predictions, gts, self.device)\n",
    "        \n",
    "        loss = torch.sum(dists)\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([691, 32, 258])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MinLoss(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 0.]\n",
      " [3. 1.]]\n",
      "[[2 0]\n",
      " [3 1]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 0.]\n",
      " [2. 1.]]\n",
      "[[3 0]\n",
      " [2 1]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[2. 1.]\n",
      " [3. 0.]]\n",
      "[[2 1]\n",
      " [3 0]]\n",
      "[[3. 1.]\n",
      " [2. 0.]]\n",
      "[[3 1]\n",
      " [2 0]]\n",
      "[[[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 0]\n",
      "  [3 1]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 0]\n",
      "  [2 1]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[2 1]\n",
      "  [3 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [2 0]]]\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(preds, ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2107870.5000, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer.step()\n",
    "preds2 = net(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[36350.96437999 29521.10932088]\n",
      "  [36350.63699262 29520.51273838]]\n",
      "\n",
      " [[36346.080315   29447.16830141]\n",
      "  [36346.27510187 29447.79018782]]\n",
      "\n",
      " [[36315.9513054  29578.25487447]\n",
      "  [36316.15794433 29578.28825781]]\n",
      "\n",
      " [[36351.21529042 29578.41109664]\n",
      "  [36351.07756996 29578.21997653]]\n",
      "\n",
      " [[36341.08126093 29580.12531119]\n",
      "  [36341.39591655 29579.6629461 ]]\n",
      "\n",
      " [[36321.7483926  29441.37101397]\n",
      "  [36321.65990421 29441.36866038]]\n",
      "\n",
      " [[36328.28371153 29516.21178883]\n",
      "  [36328.59821348 29516.80296633]]\n",
      "\n",
      " [[36346.82227578 29457.93457161]\n",
      "  [36347.49076438 29457.63527482]]\n",
      "\n",
      " [[36331.01925345 29549.84642059]\n",
      "  [36331.88643813 29549.96546081]]\n",
      "\n",
      " [[36349.72786053 29505.87464815]\n",
      "  [36349.87985068 29505.92352079]]\n",
      "\n",
      " [[36308.87534222 29529.6131852 ]\n",
      "  [36309.5413424  29529.65153648]]\n",
      "\n",
      " [[36318.02847037 29538.97988932]\n",
      "  [36318.51562363 29538.61102112]]\n",
      "\n",
      " [[36348.1849275  29455.70799655]\n",
      "  [36348.48093283 29455.46173102]]\n",
      "\n",
      " [[36345.11974964 29597.26365491]\n",
      "  [36345.54902772 29596.87524299]]\n",
      "\n",
      " [[36343.67892849 29480.01377661]\n",
      "  [36344.189181   29480.08102675]]\n",
      "\n",
      " [[36302.36469826 29448.92415653]\n",
      "  [36301.97014146 29447.91953556]]\n",
      "\n",
      " [[36297.12024765 29561.03478265]\n",
      "  [36296.86270904 29560.3444258 ]]\n",
      "\n",
      " [[36345.70860799 29594.6405549 ]\n",
      "  [36345.83703178 29594.52770946]]\n",
      "\n",
      " [[36326.07082737 29505.33560232]\n",
      "  [36326.43434187 29504.49355677]]\n",
      "\n",
      " [[36308.13445764 29580.51421872]\n",
      "  [36307.42561716 29580.1227727 ]]\n",
      "\n",
      " [[36324.55612165 29462.20753818]\n",
      "  [36324.1095548  29461.99032585]]\n",
      "\n",
      " [[36330.72569876 29566.92870983]\n",
      "  [36331.45089076 29566.16698823]]\n",
      "\n",
      " [[36330.41716226 29597.2627882 ]\n",
      "  [36331.11780212 29597.14930835]]\n",
      "\n",
      " [[36323.03193101 29464.17726032]\n",
      "  [36323.02670685 29464.17251103]]\n",
      "\n",
      " [[36306.54497649 29581.68625352]\n",
      "  [36306.27506715 29581.24764655]]\n",
      "\n",
      " [[36345.98067413 29465.59237493]\n",
      "  [36346.40185655 29464.93327359]]\n",
      "\n",
      " [[36301.36366289 29598.39980661]\n",
      "  [36301.21256462 29598.69097541]]\n",
      "\n",
      " [[36298.63116507 29444.53737671]\n",
      "  [36298.79876372 29444.4862899 ]]\n",
      "\n",
      " [[36342.57200842 29597.58584898]\n",
      "  [36342.36295069 29597.44008059]]\n",
      "\n",
      " [[36345.70910417 29593.24839254]\n",
      "  [36345.8379017  29592.4392755 ]]\n",
      "\n",
      " [[36352.47159997 29495.37731017]\n",
      "  [36352.56702306 29495.04145078]]\n",
      "\n",
      " [[36298.79550754 29536.83602136]\n",
      "  [36298.79228002 29536.19794881]]]\n",
      "[[[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]\n",
      "\n",
      " [[4 4]\n",
      "  [4 4]]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[36350.96437999 29521.10932088]\n",
      " [36350.63699262 29520.51273838]]\n",
      "[0. 1.]\n",
      "[[36346.080315   29447.16830141]\n",
      " [36346.27510187 29447.79018782]]\n",
      "[1. 0.]\n",
      "[[36315.9513054  29578.25487447]\n",
      " [36316.15794433 29578.28825781]]\n",
      "[1. 0.]\n",
      "[[36351.21529042 29578.41109664]\n",
      " [36351.07756996 29578.21997653]]\n",
      "[0. 1.]\n",
      "[[36341.08126093 29580.12531119]\n",
      " [36341.39591655 29579.6629461 ]]\n",
      "[0. 1.]\n",
      "[[36321.7483926  29441.37101397]\n",
      " [36321.65990421 29441.36866038]]\n",
      "[0. 1.]\n",
      "[[36328.28371153 29516.21178883]\n",
      " [36328.59821348 29516.80296633]]\n",
      "[1. 0.]\n",
      "[[36346.82227578 29457.93457161]\n",
      " [36347.49076438 29457.63527482]]\n",
      "[0. 1.]\n",
      "[[36331.01925345 29549.84642059]\n",
      " [36331.88643813 29549.96546081]]\n",
      "[1. 0.]\n",
      "[[36349.72786053 29505.87464815]\n",
      " [36349.87985068 29505.92352079]]\n",
      "[1. 0.]\n",
      "[[36308.87534222 29529.6131852 ]\n",
      " [36309.5413424  29529.65153648]]\n",
      "[1. 0.]\n",
      "[[36318.02847037 29538.97988932]\n",
      " [36318.51562363 29538.61102112]]\n",
      "[0. 1.]\n",
      "[[36348.1849275  29455.70799655]\n",
      " [36348.48093283 29455.46173102]]\n",
      "[0. 1.]\n",
      "[[36345.11974964 29597.26365491]\n",
      " [36345.54902772 29596.87524299]]\n",
      "[0. 1.]\n",
      "[[36343.67892849 29480.01377661]\n",
      " [36344.189181   29480.08102675]]\n",
      "[1. 0.]\n",
      "[[36302.36469826 29448.92415653]\n",
      " [36301.97014146 29447.91953556]]\n",
      "[0. 1.]\n",
      "[[36297.12024765 29561.03478265]\n",
      " [36296.86270904 29560.3444258 ]]\n",
      "[0. 1.]\n",
      "[[36345.70860799 29594.6405549 ]\n",
      " [36345.83703178 29594.52770946]]\n",
      "[0. 1.]\n",
      "[[36326.07082737 29505.33560232]\n",
      " [36326.43434187 29504.49355677]]\n",
      "[0. 1.]\n",
      "[[36308.13445764 29580.51421872]\n",
      " [36307.42561716 29580.1227727 ]]\n",
      "[0. 1.]\n",
      "[[36324.55612165 29462.20753818]\n",
      " [36324.1095548  29461.99032585]]\n",
      "[0. 1.]\n",
      "[[36330.72569876 29566.92870983]\n",
      " [36331.45089076 29566.16698823]]\n",
      "[0. 1.]\n",
      "[[36330.41716226 29597.2627882 ]\n",
      " [36331.11780212 29597.14930835]]\n",
      "[0. 1.]\n",
      "[[36323.03193101 29464.17726032]\n",
      " [36323.02670685 29464.17251103]]\n",
      "[0. 1.]\n",
      "[[36306.54497649 29581.68625352]\n",
      " [36306.27506715 29581.24764655]]\n",
      "[0. 1.]\n",
      "[[36345.98067413 29465.59237493]\n",
      " [36346.40185655 29464.93327359]]\n",
      "[0. 1.]\n",
      "[[36301.36366289 29598.39980661]\n",
      " [36301.21256462 29598.69097541]]\n",
      "[1. 0.]\n",
      "[[36298.63116507 29444.53737671]\n",
      " [36298.79876372 29444.4862899 ]]\n",
      "[0. 1.]\n",
      "[[36342.57200842 29597.58584898]\n",
      " [36342.36295069 29597.44008059]]\n",
      "[0. 1.]\n",
      "[[36345.70910417 29593.24839254]\n",
      " [36345.8379017  29592.4392755 ]]\n",
      "[0. 1.]\n",
      "[[36352.47159997 29495.37731017]\n",
      " [36352.56702306 29495.04145078]]\n",
      "[0. 1.]\n",
      "[[36298.79550754 29536.83602136]\n",
      " [36298.79228002 29536.19794881]]\n",
      "[0. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2107392., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = criterion(preds2, ground_truths)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([32, 173, 1025])\n",
      "torch.Size([173, 1025])\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truths))\n",
    "print(ground_truths[0].size())\n",
    "gt = net.reshape(ground_truths[0])\n",
    "print(torch.squeeze(gt[:, 0, :], dim=1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 173, 1025])\n",
      "tensor([1.4197e-19, 9.8981e-19, 1.4690e-17,  ..., 8.6916e-19, 1.9786e-18,\n",
      "        1.6256e-18])\n",
      "tensor([1.4197e-19, 9.8981e-19, 1.4690e-17,  ..., 8.6916e-19, 1.9786e-18,\n",
      "        1.6256e-18])\n",
      "torch.Size([173, 32, 1025])\n"
     ]
    }
   ],
   "source": [
    "# print(aggregate[:, 0])\n",
    "# agg = torch.t(aggregate)\n",
    "# print(agg[0, :])\n",
    "print(aggregate.size())\n",
    "print(aggregate[1, 1, :])\n",
    "seq_len = aggregate.size()[1]\n",
    "aggs = [aggregate[:, t, :] for t in range(seq_len)]\n",
    "x = torch.cat(aggs).view(173, bs, -1)\n",
    "print(x[1, 1, :])\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [12, 13, 14, 15]])\n",
      "[ 0  1  2  3 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# from scipy.spatial import distance\n",
    "a = np.arange(15).reshape(3,5)\n",
    "b = np.random.randint(5, size=(3, 5))\n",
    "# print(a)\n",
    "# print(b)\n",
    "# a.reshape(1, 5) - b.reshape(5, 1)\n",
    "\n",
    "# distance.cdist(a, b)\n",
    "\n",
    "# a.flatten()\n",
    "\n",
    "\n",
    "t = torch.arange(24).view(2, 3, -1)\n",
    "\n",
    "print(t)\n",
    "print(t[:, 0, :])\n",
    "print(t[:, 0, :].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# m = np.zeros((2, 3, 4))\n",
    "# m[0] = np.arange(12).reshape(3,4)\n",
    "# m[1] = np.arange(12).reshape(3,4) * 2\n",
    "\n",
    "# m_c = concat(m)\n",
    "\n",
    "def check(m_c, m):\n",
    "    for i in range(m_c.shape[0]):\n",
    "        for j in range(m_c.shape[1]):\n",
    "            batch = i // m.shape[1]\n",
    "            ii = i % m.shape[1]\n",
    "            assert(m_c[i][j] == m[batch][ii][j])\n",
    "    print(\"passed\")\n",
    "\n",
    "check(agg_concat, agg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
